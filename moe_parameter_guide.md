# MoE参数调优指南

## 🎯 调优目标
通过系统性的参数测试，找到MoE模块的最佳配置，实现相比baseline的显著性能提升。

## 🔧 可调参数详解

### 1. **MoE核心参数** (高优先级)

#### 1.1 专家网络隐藏层维度 (`MOE_EXPERT_HIDDEN_DIM`)
- **作用**: 控制专家网络的容量和表达能力
- **可调范围**: 512, 1024, 2048, 4096
- **影响**: 越大表达能力越强，但计算开销越大
- **建议**: 从1024开始，逐步测试

#### 1.2 门控网络温度参数 (`MOE_TEMPERATURE`)
- **作用**: 控制专家权重分布的尖锐程度
- **可调范围**: 0.3, 0.5, 0.7, 1.0, 1.5
- **影响**: 越小权重分布越尖锐，专家分工越明确
- **建议**: 从0.7开始，测试0.3-1.5范围

### 2. **MoE网络结构参数** (中优先级)

#### 2.1 专家网络层数 (`MOE_EXPERT_LAYERS`)
- **作用**: 控制专家网络的深度
- **可调范围**: 1, 2, 3, 4
- **影响**: 越深特征变换能力越强，但训练越困难
- **建议**: 从2层开始测试

#### 2.2 门控网络层数 (`MOE_GATE_LAYERS`)
- **作用**: 控制门控网络的决策复杂度
- **可调范围**: 1, 2, 3
- **影响**: 越深决策越复杂，但可能过拟合
- **建议**: 从2层开始测试

#### 2.3 专家激活阈值 (`MOE_EXPERT_THRESHOLD`)
- **作用**: 控制专家激活的敏感性
- **可调范围**: 0.0, 0.1, 0.2, 0.3
- **影响**: 越小专家激活越敏感
- **建议**: 从0.1开始测试

### 3. **MoE正则化参数** (中优先级)

#### 3.1 专家网络Dropout (`MOE_EXPERT_DROPOUT`)
- **作用**: 防止专家网络过拟合
- **可调范围**: 0.0, 0.1, 0.2, 0.3
- **影响**: 越大正则化越强，但可能欠拟合
- **建议**: 从0.1开始测试

#### 3.2 门控网络Dropout (`MOE_GATE_DROPOUT`)
- **作用**: 防止门控网络过拟合
- **可调范围**: 0.0, 0.1, 0.2, 0.3
- **影响**: 越大门控决策越稳定
- **建议**: 从0.1开始测试

### 4. **MoE损失权重参数** (低优先级)

#### 4.1 专家平衡损失权重 (`MOE_BALANCE_LOSS_WEIGHT`)
- **作用**: 促进专家使用平衡
- **可调范围**: 0.0, 0.01, 0.1, 1.0
- **影响**: 越大专家使用越平衡
- **建议**: 从0.01开始测试

#### 4.2 稀疏性损失权重 (`MOE_SPARSITY_LOSS_WEIGHT`)
- **作用**: 促进专家选择稀疏性
- **可调范围**: 0.0, 0.001, 0.01, 0.1
- **影响**: 越大专家选择越稀疏
- **建议**: 从0.001开始测试

#### 4.3 多样性损失权重 (`MOE_DIVERSITY_LOSS_WEIGHT`)
- **作用**: 促进专家分工多样性
- **可调范围**: 0.0, 0.01, 0.1, 1.0
- **影响**: 越大专家分工越多样
- **建议**: 从0.01开始测试

## 🚀 调优策略

### 策略1: 渐进式调优 (推荐)
1. **第一步**: 测试核心参数 (专家维度 + 温度)
2. **第二步**: 测试网络结构 (层数 + 阈值)
3. **第三步**: 测试正则化 (Dropout)
4. **第四步**: 测试损失权重

### 策略2: 聚焦搜索
基于经验的重点参数组合测试

### 策略3: 网格搜索
系统性地测试所有参数组合

## 📊 实验记录

### 记录内容
- 实验ID和时间戳
- 参数配置
- 训练结果 (mAP, Rank-1, Rank-5)
- 训练时间
- 实验状态

### 结果分析
- 性能对比
- 参数敏感性分析
- 最佳配置推荐

## 🛠️ 使用方法

### 1. 快速单次测试
```bash
# 测试特定参数组合
python moe_quick_test.py test1 MOE_EXPERT_HIDDEN_DIM=1024 MOE_TEMPERATURE=0.7

# 测试不同专家维度
python moe_quick_test.py test2 MOE_EXPERT_HIDDEN_DIM=2048 MOE_TEMPERATURE=0.5

# 测试不同温度
python moe_quick_test.py test3 MOE_EXPERT_HIDDEN_DIM=1024 MOE_TEMPERATURE=0.3
```

### 2. 系统性调优
```bash
# 聚焦搜索 (推荐)
python moe_hyperparameter_tuning.py --strategy focused_search --max_experiments 10

# 随机搜索
python moe_hyperparameter_tuning.py --strategy random_search --max_experiments 20

# 网格搜索
python moe_hyperparameter_tuning.py --strategy grid_search --max_experiments 50
```

### 3. 结果分析
```bash
# 查看实验结果
ls moe_tuning_logs/
ls moe_quick_tests/

# 查看最佳结果
cat moe_tuning_logs/tuning_report.json
cat moe_quick_tests/quick_test_summary.json
```

## 📈 预期效果

### 性能提升目标
- **mAP提升**: +2% 以上
- **Rank-1提升**: +2% 以上
- **训练稳定性**: 损失曲线平滑下降

### 专家分析指标
- **专家平衡度**: 各专家使用频率方差 < 0.1
- **专家激活率**: 平均激活率 > 0.8
- **门控稳定性**: 权重分布方差 < 0.05

## 🔍 调试建议

### 1. 参数调试顺序
1. **专家维度**: 512 → 1024 → 2048
2. **温度参数**: 0.3 → 0.5 → 0.7 → 1.0 → 1.5
3. **网络层数**: 1 → 2 → 3
4. **Dropout**: 0.0 → 0.1 → 0.2

### 2. 常见问题
- **性能下降**: 检查温度参数和专家维度
- **训练不稳定**: 检查Dropout和损失权重
- **专家不平衡**: 调整平衡损失权重

### 3. 最佳实践
- 每次只调整1-2个参数
- 记录每次实验的完整配置
- 对比baseline性能
- 分析专家权重分布

## 📝 实验记录模板

### 实验记录格式
```json
{
  "experiment_id": "moe_test_001",
  "experiment_name": "专家维度测试",
  "start_time": "2024-01-01T10:00:00",
  "parameters": {
    "MOE_EXPERT_HIDDEN_DIM": 1024,
    "MOE_TEMPERATURE": 0.7,
    "MOE_EXPERT_DROPOUT": 0.1
  },
  "results": {
    "mAP": 85.2,
    "Rank-1": 92.1,
    "Rank-5": 96.8
  },
  "status": "completed"
}
```

### 结果对比表
| 实验ID | 专家维度 | 温度 | mAP | Rank-1 | 状态 |
|--------|----------|------|-----|--------|------|
| test1  | 512      | 0.7  | 83.1 | 90.2   | 完成 |
| test2  | 1024     | 0.7  | 85.2 | 92.1   | 完成 |
| test3  | 2048     | 0.7  | 84.8 | 91.8   | 完成 |

## 🎯 成功标准

### 性能标准
- mAP > baseline + 2%
- Rank-1 > baseline + 2%
- 训练稳定，无异常

### 专家标准
- 专家使用平衡
- 权重分布合理
- 激活模式清晰

### 效率标准
- 训练时间合理
- 内存使用可控
- 推理速度可接受

通过系统性的参数调优，找到MoE模块的最佳配置，实现显著的性能提升！
