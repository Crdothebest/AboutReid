# CLIPåˆ†æ”¯ vs å¤šå°ºåº¦åˆ†æ”¯å…±å­˜é—®é¢˜è¯¦è§£

## ğŸ¤” **é—®é¢˜æ ¸å¿ƒ**

**ä¸ºä»€ä¹ˆCLIPåˆ†æ”¯å’Œå¤šå°ºåº¦åˆ†æ”¯ä¸å¯å…±å­˜ï¼Ÿå®ƒä»¬å„è‡ªä»€ä¹ˆåŠŸèƒ½ï¼Ÿ**

## ğŸ“‹ **ä¸¤ä¸ªåˆ†æ”¯çš„åŠŸèƒ½å¯¹æ¯”**

### **CLIPåˆ†æ”¯åŠŸèƒ½**
```python
# CLIPåˆ†æ”¯çš„æ ¸å¿ƒåŠŸèƒ½
if self.clip == 1:  # CLIPåˆ†æ”¯
    # 1. ç›¸æœº/è§†è§’åµŒå…¥å¤„ç†
    cv_embed = self.sie_xishu * self.cv_embed[cam_label]
    
    # 2. CLIPæ¨¡å‹å‰å‘ä¼ æ’­
    x = self.base(x, cv_embed, modality)  # CLIPç‰¹æœ‰çš„å‚æ•°ä¼ é€’
    
    # 3. è¾“å‡º512ç»´ç‰¹å¾
    global_feat = x[:, 0]  # CLIPçš„CLS token
```

**CLIPåˆ†æ”¯ç‰¹ç‚¹**ï¼š
- **å¤šæ¨¡æ€èƒ½åŠ›**: æ–‡æœ¬-å›¾åƒå¯¹æ¯”å­¦ä¹ 
- **ç‰¹å¾ç»´åº¦**: 512ç»´
- **ç›¸æœºåµŒå…¥**: æ”¯æŒç›¸æœº/è§†è§’ä¿¡æ¯åµŒå…¥
- **é¢„è®­ç»ƒæƒé‡**: CLIPé¢„è®­ç»ƒæƒé‡
- **æ¶æ„**: CLIPè§†è§‰ç¼–ç å™¨

### **å¤šå°ºåº¦åˆ†æ”¯åŠŸèƒ½**
```python
# å¤šå°ºåº¦åˆ†æ”¯çš„æ ¸å¿ƒåŠŸèƒ½
if self.clip == 0:  # å¤šå°ºåº¦åˆ†æ”¯
    # 1. æ ‡å‡†ViTå‰å‘ä¼ æ’­
    x = self.base(x, cam_label=cam_label, view_label=view_label, modality=modality)
    
    # 2. å¤šå°ºåº¦æ»‘åŠ¨çª—å£å¤„ç†
    if self.use_multi_scale:
        cls_token = x[:, 0:1, :]  # åˆ†ç¦»CLS token
        patch_tokens = x[:, 1:, :]  # åˆ†ç¦»patch tokens
        
        # å¤šå°ºåº¦ç‰¹å¾æå–
        multi_scale_feature = self.multi_scale_extractor(patch_tokens)
        
        # ç‰¹å¾èåˆ
        enhanced_cls = cls_token + multi_scale_feature.unsqueeze(1)
        x = torch.cat([enhanced_cls, patch_tokens], dim=1)
    
    # 3. è¾“å‡º768ç»´ç‰¹å¾
    global_feat = x[:, 0]  # å¢å¼ºçš„CLS token
```

**å¤šå°ºåº¦åˆ†æ”¯ç‰¹ç‚¹**ï¼š
- **å¤šå°ºåº¦èƒ½åŠ›**: æ»‘åŠ¨çª—å£ç‰¹å¾æå–
- **ç‰¹å¾ç»´åº¦**: 768ç»´
- **ç©ºé—´æ„ŸçŸ¥**: 4x4ã€8x8ã€16x16å¤šå°ºåº¦å¤„ç†
- **é¢„è®­ç»ƒæƒé‡**: ImageNeté¢„è®­ç»ƒæƒé‡
- **æ¶æ„**: æ ‡å‡†ViTæ¶æ„

## ğŸš« **ä¸ºä»€ä¹ˆä¸å¯å…±å­˜ï¼Ÿ**

### **1. æ¶æ„ä¸å…¼å®¹**

#### **CLIPæ¶æ„ç‰¹ç‚¹**ï¼š
```python
# CLIPæ¨¡å‹çš„å‰å‘ä¼ æ’­
def forward(self, x, cv_embed, modality):
    # CLIPç‰¹æœ‰çš„å‚æ•°ä¼ é€’æ–¹å¼
    # cv_embed: ç›¸æœºåµŒå…¥
    # modality: æ¨¡æ€ä¿¡æ¯
    return clip_features  # 512ç»´
```

#### **æ ‡å‡†ViTæ¶æ„ç‰¹ç‚¹**ï¼š
```python
# æ ‡å‡†ViTçš„å‰å‘ä¼ æ’­
def forward(self, x, cam_label, view_label, modality):
    # æ ‡å‡†ViTçš„å‚æ•°ä¼ é€’æ–¹å¼
    # cam_label: ç›¸æœºæ ‡ç­¾
    # view_label: è§†è§’æ ‡ç­¾
    # modality: æ¨¡æ€ä¿¡æ¯
    return vit_features  # 768ç»´
```

**é—®é¢˜**: å‚æ•°ä¼ é€’æ–¹å¼å®Œå…¨ä¸åŒï¼Œæ— æ³•ç›´æ¥å…¼å®¹ï¼

### **2. ç‰¹å¾ç»´åº¦ä¸åŒ¹é…**

#### **CLIPç‰¹å¾ç»´åº¦**ï¼š
```python
# CLIPè¾“å‡º
x = self.base(x, cv_embed, modality)  # [B, N+1, 512]
global_feat = x[:, 0]  # [B, 512]
```

#### **å¤šå°ºåº¦ç‰¹å¾ç»´åº¦**ï¼š
```python
# å¤šå°ºåº¦è¾“å‡º
x = self.base(x, ...)  # [B, N+1, 768]
multi_scale_feature = self.multi_scale_extractor(patch_tokens)  # [B, 768]
enhanced_cls = cls_token + multi_scale_feature.unsqueeze(1)  # [B, 1, 768]
```

**é—®é¢˜**: 512ç»´ vs 768ç»´ï¼Œç»´åº¦ä¸åŒ¹é…ï¼

### **3. å¤šå°ºåº¦æ¨¡å—è®¾è®¡é™åˆ¶**

```python
# å¤šå°ºåº¦æ¨¡å—æ˜¯ä¸ºæ ‡å‡†ViTè®¾è®¡çš„
class MultiScaleFeatureExtractor:
    def __init__(self, feat_dim, scales=[4, 8, 16]):
        self.feat_dim = feat_dim  # æœŸæœ›768ç»´
        # æ»‘åŠ¨çª—å£å¤„ç†é€»è¾‘
```

**é—®é¢˜**: å¤šå°ºåº¦æ¨¡å—æœŸæœ›768ç»´è¾“å…¥ï¼ŒCLIPåªæœ‰512ç»´ï¼

### **4. å‰å‘ä¼ æ’­é€»è¾‘å†²çª**

```python
def forward(self, x, ...):
    if self.clip == 0:  # å¤šå°ºåº¦åˆ†æ”¯
        # æ ‡å‡†ViTå¤„ç† + å¤šå°ºåº¦å¤„ç†
        x = self.base(x, cam_label=cam_label, view_label=view_label, modality=modality)
        if self.use_multi_scale:
            # å¤šå°ºåº¦æ»‘åŠ¨çª—å£å¤„ç†
    else:  # CLIPåˆ†æ”¯
        # CLIPå¤„ç†
        x = self.base(x, cv_embed, modality)
```

**é—®é¢˜**: ä¸¤ä¸ªåˆ†æ”¯çš„å‰å‘ä¼ æ’­é€»è¾‘å®Œå…¨ä¸åŒï¼Œæ— æ³•åŒæ—¶æ‰§è¡Œï¼

## ğŸ”§ **æŠ€æœ¯å±‚é¢çš„ä¸å…¼å®¹**

### **1. æ¨¡å‹åŠ è½½æ–¹å¼ä¸åŒ**

#### **CLIPåˆ†æ”¯**ï¼š
```python
# åŠ è½½CLIPæ¨¡å‹
clip_model = load_clip_to_cpu(cfg, ...)
self.base = clip_model.visual  # ä½¿ç”¨CLIPçš„è§†è§‰ç¼–ç å™¨
```

#### **å¤šå°ºåº¦åˆ†æ”¯**ï¼š
```python
# åŠ è½½æ ‡å‡†ViTæ¨¡å‹
self.base = factory[cfg.MODEL.TRANSFORMER_TYPE](...)
self.base.load_param(model_path)  # åŠ è½½ImageNeté¢„è®­ç»ƒæƒé‡
```

### **2. ç›¸æœºåµŒå…¥å¤„ç†ä¸åŒ**

#### **CLIPåˆ†æ”¯**ï¼š
```python
# CLIPçš„ç›¸æœºåµŒå…¥
cv_embed = self.sie_xishu * self.cv_embed[cam_label]
x = self.base(x, cv_embed, modality)
```

#### **å¤šå°ºåº¦åˆ†æ”¯**ï¼š
```python
# æ ‡å‡†ViTçš„ç›¸æœºåµŒå…¥
x = self.base(x, cam_label=cam_label, view_label=view_label, modality=modality)
```

### **3. ç‰¹å¾å¤„ç†æ–¹å¼ä¸åŒ**

#### **CLIPåˆ†æ”¯**ï¼š
```python
# ç›´æ¥ä½¿ç”¨CLIPç‰¹å¾
global_feat = x[:, 0]  # 512ç»´CLIPç‰¹å¾
```

#### **å¤šå°ºåº¦åˆ†æ”¯**ï¼š
```python
# å¤šå°ºåº¦å¢å¼ºç‰¹å¾
cls_token = x[:, 0:1, :]  # 768ç»´CLS token
patch_tokens = x[:, 1:, :]  # 768ç»´patch tokens
multi_scale_feature = self.multi_scale_extractor(patch_tokens)  # 768ç»´å¤šå°ºåº¦ç‰¹å¾
enhanced_cls = cls_token + multi_scale_feature.unsqueeze(1)  # 768ç»´å¢å¼ºç‰¹å¾
```

## ğŸ’¡ **ä¸ºä»€ä¹ˆä¸èƒ½ç®€å•åˆå¹¶ï¼Ÿ**

### **å°è¯•1: åœ¨CLIPåŸºç¡€ä¸Šæ·»åŠ å¤šå°ºåº¦**
```python
# è¿™æ ·åšä¼šå¤±è´¥
if self.clip == 1:  # CLIPåˆ†æ”¯
    x = self.base(x, cv_embed, modality)  # è¾“å‡º512ç»´
    if self.use_multi_scale:
        # é—®é¢˜ï¼šå¤šå°ºåº¦æ¨¡å—æœŸæœ›768ç»´è¾“å…¥ï¼Œä½†CLIPåªæœ‰512ç»´
        multi_scale_feature = self.multi_scale_extractor(x)  # ç»´åº¦ä¸åŒ¹é…ï¼
```

### **å°è¯•2: åœ¨æ ‡å‡†ViTåŸºç¡€ä¸Šæ·»åŠ CLIPåŠŸèƒ½**
```python
# è¿™æ ·åšä¹Ÿä¼šå¤±è´¥
if self.clip == 0:  # å¤šå°ºåº¦åˆ†æ”¯
    x = self.base(x, cam_label=cam_label, view_label=view_label, modality=modality)
    if self.use_multi_scale:
        # å¤šå°ºåº¦å¤„ç†
    # é—®é¢˜ï¼šCLIPçš„ç›¸æœºåµŒå…¥é€»è¾‘æ— æ³•ç›´æ¥åº”ç”¨
    cv_embed = self.sie_xishu * self.cv_embed[cam_label]  # è¿™ä¸ªé€»è¾‘ä¸é€‚ç”¨äºæ ‡å‡†ViT
```

## ğŸ¯ **è§£å†³æ–¹æ¡ˆ**

### **æ–¹æ¡ˆ1: åˆ†æ”¯é€‰æ‹©ï¼ˆå½“å‰æ–¹æ¡ˆï¼‰**
```python
# æ ¹æ®é…ç½®é€‰æ‹©åˆ†æ”¯
if cfg.MODEL.TRANSFORMER_TYPE == 'ViT-B-16':
    self.clip = 0  # èµ°å¤šå°ºåº¦åˆ†æ”¯
elif cfg.MODEL.TRANSFORMER_TYPE == 'ViT-B-16-CLIP':
    self.clip = 1  # èµ°CLIPåˆ†æ”¯
```

### **æ–¹æ¡ˆ2: ç»Ÿä¸€æ¶æ„ï¼ˆå¤æ‚æ–¹æ¡ˆï¼‰**
```python
# éœ€è¦é‡æ–°è®¾è®¡å¤šå°ºåº¦æ¨¡å—ï¼Œä½¿å…¶å…¼å®¹CLIP
class CLIPCompatibleMultiScale:
    def __init__(self, feat_dim=512, scales=[4, 8, 16]):
        # é€‚é…CLIPçš„512ç»´ç‰¹å¾
        pass
```

### **æ–¹æ¡ˆ3: æ··åˆæ¶æ„ï¼ˆæœ€å¤æ‚æ–¹æ¡ˆï¼‰**
```python
# éœ€è¦åŒæ—¶æ”¯æŒä¸¤ç§æ¶æ„
class HybridModel:
    def __init__(self):
        self.clip_model = load_clip_model()
        self.vit_model = load_vit_model()
        self.multi_scale = MultiScaleFeatureExtractor()
    
    def forward(self, x, use_clip=True, use_multi_scale=True):
        if use_clip:
            clip_feat = self.clip_model(x)
        if use_multi_scale:
            vit_feat = self.vit_model(x)
            multi_scale_feat = self.multi_scale(vit_feat)
        # èåˆä¸¤ç§ç‰¹å¾
```

## ğŸ“Š **æ€»ç»“**

### **ä¸å¯å…±å­˜çš„åŸå› **ï¼š
1. **æ¶æ„ä¸å…¼å®¹**: CLIPå’Œæ ‡å‡†ViTçš„å‰å‘ä¼ æ’­æ–¹å¼ä¸åŒ
2. **ç‰¹å¾ç»´åº¦ä¸åŒ¹é…**: 512ç»´ vs 768ç»´
3. **å‚æ•°ä¼ é€’æ–¹å¼ä¸åŒ**: cv_embed vs cam_label/view_label
4. **å¤šå°ºåº¦æ¨¡å—è®¾è®¡é™åˆ¶**: ä¸“ä¸ºæ ‡å‡†ViTè®¾è®¡
5. **å‰å‘ä¼ æ’­é€»è¾‘å†²çª**: ä¸¤ä¸ªåˆ†æ”¯çš„å¤„ç†æµç¨‹å®Œå…¨ä¸åŒ

### **å„è‡ªçš„åŠŸèƒ½**ï¼š
- **CLIPåˆ†æ”¯**: å¤šæ¨¡æ€èƒ½åŠ›ã€ç›¸æœºåµŒå…¥ã€512ç»´ç‰¹å¾
- **å¤šå°ºåº¦åˆ†æ”¯**: å¤šå°ºåº¦æ„ŸçŸ¥ã€ç©ºé—´ç‰¹å¾æå–ã€768ç»´ç‰¹å¾

### **å½“å‰è§£å†³æ–¹æ¡ˆ**ï¼š
é€šè¿‡é…ç½®é€‰æ‹©åˆ†æ”¯ï¼Œå®ç°åŠŸèƒ½åˆ†ç¦»ï¼Œé¿å…æ¶æ„å†²çªã€‚è¿™æ ·æ—¢ä¿æŒäº†ä»£ç çš„æ¸…æ™°æ€§ï¼Œåˆç¡®ä¿äº†åŠŸèƒ½çš„æ­£ç¡®æ€§ã€‚

## ğŸ”® **æœªæ¥å¯èƒ½çš„æ”¹è¿›**

å¦‚æœè¦å®ç°çœŸæ­£çš„å…±å­˜ï¼Œéœ€è¦ï¼š
1. é‡æ–°è®¾è®¡å¤šå°ºåº¦æ¨¡å—ï¼Œä½¿å…¶å…¼å®¹CLIP
2. ç»Ÿä¸€ç‰¹å¾ç»´åº¦å¤„ç†
3. è®¾è®¡ç»Ÿä¸€çš„å‚æ•°ä¼ é€’æ¥å£
4. å®ç°ç‰¹å¾èåˆæœºåˆ¶

ä½†è¿™ä¼šå¤§å¤§å¢åŠ ä»£ç å¤æ‚åº¦ï¼Œå½“å‰çš„åˆ†æ”¯é€‰æ‹©æ–¹æ¡ˆæ˜¯æœ€å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ” **å…·ä½“ä»£ç ç¤ºä¾‹è¯´æ˜**

### **ç¤ºä¾‹1: å‚æ•°ä¼ é€’ä¸å…¼å®¹**

#### **CLIPåˆ†æ”¯çš„å‚æ•°ä¼ é€’**ï¼š
```python
# CLIPæ¨¡å‹æœŸæœ›çš„å‚æ•°
def clip_forward(self, x, cv_embed, modality):
    # cv_embed: [B, 512] - ç›¸æœºåµŒå…¥å‘é‡
    # modality: str - æ¨¡æ€ä¿¡æ¯
    return features

# è°ƒç”¨æ–¹å¼
x = self.base(x, cv_embed, modality)
```

#### **æ ‡å‡†ViTçš„å‚æ•°ä¼ é€’**ï¼š
```python
# æ ‡å‡†ViTæœŸæœ›çš„å‚æ•°
def vit_forward(self, x, cam_label, view_label, modality):
    # cam_label: [B] - ç›¸æœºæ ‡ç­¾
    # view_label: [B] - è§†è§’æ ‡ç­¾  
    # modality: str - æ¨¡æ€ä¿¡æ¯
    return features

# è°ƒç”¨æ–¹å¼
x = self.base(x, cam_label=cam_label, view_label=view_label, modality=modality)
```

**é—®é¢˜**: å‚æ•°åç§°ã€ç±»å‹ã€ä¼ é€’æ–¹å¼å®Œå…¨ä¸åŒï¼

### **ç¤ºä¾‹2: ç‰¹å¾ç»´åº¦ä¸åŒ¹é…**

#### **CLIPç‰¹å¾å¤„ç†**ï¼š
```python
# CLIPè¾“å‡ºç‰¹å¾
x = self.base(x, cv_embed, modality)  # [B, N+1, 512]
global_feat = x[:, 0]  # [B, 512]

# å¦‚æœå°è¯•åº”ç”¨å¤šå°ºåº¦å¤„ç†
cls_token = x[:, 0:1, :]  # [B, 1, 512]
patch_tokens = x[:, 1:, :]  # [B, N, 512]

# å¤šå°ºåº¦æ¨¡å—æœŸæœ›768ç»´è¾“å…¥
multi_scale_feature = self.multi_scale_extractor(patch_tokens)  # é”™è¯¯ï¼ç»´åº¦ä¸åŒ¹é…
```

#### **å¤šå°ºåº¦ç‰¹å¾å¤„ç†**ï¼š
```python
# æ ‡å‡†ViTè¾“å‡ºç‰¹å¾
x = self.base(x, cam_label=cam_label, view_label=view_label, modality=modality)  # [B, N+1, 768]
cls_token = x[:, 0:1, :]  # [B, 1, 768]
patch_tokens = x[:, 1:, :]  # [B, N, 768]

# å¤šå°ºåº¦æ¨¡å—æ­£å¸¸å·¥ä½œ
multi_scale_feature = self.multi_scale_extractor(patch_tokens)  # [B, 768] - æ­£ç¡®ï¼
```

### **ç¤ºä¾‹3: ç›¸æœºåµŒå…¥å¤„ç†ä¸å…¼å®¹**

#### **CLIPçš„ç›¸æœºåµŒå…¥**ï¼š
```python
# CLIPåˆ†æ”¯
if self.cv_embed_sign:
    cv_embed = self.sie_xishu * self.cv_embed[cam_label]  # [B, 512]
else:
    cv_embed = None
x = self.base(x, cv_embed, modality)
```

#### **æ ‡å‡†ViTçš„ç›¸æœºåµŒå…¥**ï¼š
```python
# å¤šå°ºåº¦åˆ†æ”¯
x = self.base(x, cam_label=cam_label, view_label=view_label, modality=modality)
# ç›¸æœºåµŒå…¥åœ¨ViTå†…éƒ¨å¤„ç†ï¼Œä¸éœ€è¦å¤–éƒ¨ä¼ å…¥
```

**é—®é¢˜**: ç›¸æœºåµŒå…¥çš„å¤„ç†æ–¹å¼å®Œå…¨ä¸åŒï¼

### **ç¤ºä¾‹4: å¤šå°ºåº¦æ¨¡å—è®¾è®¡é™åˆ¶**

```python
class MultiScaleFeatureExtractor:
    def __init__(self, feat_dim, scales=[4, 8, 16]):
        self.feat_dim = feat_dim  # æœŸæœ›768ç»´
        self.scales = scales
        
        # æ»‘åŠ¨çª—å£å¤„ç†å±‚
        self.sliding_windows = nn.ModuleList([
            nn.Conv2d(feat_dim, feat_dim, kernel_size=scale, stride=scale)
            for scale in scales
        ])
    
    def forward(self, patch_tokens):
        # patch_tokens: [B, N, feat_dim] - æœŸæœ›768ç»´
        # å¦‚æœè¾“å…¥æ˜¯512ç»´ï¼Œè¿™é‡Œä¼šå‡ºé”™
        return multi_scale_features
```

**é—®é¢˜**: å¤šå°ºåº¦æ¨¡å—ç¡¬ç¼–ç äº†768ç»´ï¼Œæ— æ³•å¤„ç†CLIPçš„512ç»´ç‰¹å¾ï¼

## ğŸ¯ **å®é™…è¿è¡Œæ—¶çš„é”™è¯¯ç¤ºä¾‹**

### **å¦‚æœå¼ºåˆ¶è®©CLIPåˆ†æ”¯ä½¿ç”¨å¤šå°ºåº¦æ¨¡å—**ï¼š

```python
# é”™è¯¯çš„å°è¯•
if self.clip == 1:  # CLIPåˆ†æ”¯
    x = self.base(x, cv_embed, modality)  # è¾“å‡º [B, N+1, 512]
    
    # å°è¯•åº”ç”¨å¤šå°ºåº¦å¤„ç†
    if self.use_multi_scale:
        cls_token = x[:, 0:1, :]  # [B, 1, 512]
        patch_tokens = x[:, 1:, :]  # [B, N, 512]
        
        # è¿™é‡Œä¼šå‡ºé”™ï¼
        multi_scale_feature = self.multi_scale_extractor(patch_tokens)
        # é”™è¯¯ï¼šæœŸæœ›è¾“å…¥768ç»´ï¼Œä½†å¾—åˆ°512ç»´
        # RuntimeError: size mismatch, expected 768, got 512
```

### **å¦‚æœå¼ºåˆ¶è®©å¤šå°ºåº¦åˆ†æ”¯ä½¿ç”¨CLIPå‚æ•°**ï¼š

```python
# é”™è¯¯çš„å°è¯•
if self.clip == 0:  # å¤šå°ºåº¦åˆ†æ”¯
    # å°è¯•ä½¿ç”¨CLIPçš„å‚æ•°ä¼ é€’æ–¹å¼
    x = self.base(x, cv_embed, modality)  # é”™è¯¯ï¼
    # é”™è¯¯ï¼šæ ‡å‡†ViTä¸æ¥å—cv_embedå‚æ•°
    # TypeError: forward() got an unexpected keyword argument 'cv_embed'
```

## ğŸ’¡ **ä¸ºä»€ä¹ˆåˆ†æ”¯é€‰æ‹©æ˜¯æœ€ä½³æ–¹æ¡ˆ**

### **ä¼˜åŠ¿**ï¼š
1. **æ¶æ„æ¸…æ™°**: æ¯ä¸ªåˆ†æ”¯ä¸“æ³¨äºè‡ªå·±çš„åŠŸèƒ½
2. **ä»£ç ç®€æ´**: é¿å…å¤æ‚çš„å…¼å®¹æ€§å¤„ç†
3. **æ€§èƒ½ä¼˜åŒ–**: æ¯ä¸ªåˆ†æ”¯å¯ä»¥é’ˆå¯¹æ€§åœ°ä¼˜åŒ–
4. **ç»´æŠ¤ç®€å•**: ä¿®æ”¹ä¸€ä¸ªåˆ†æ”¯ä¸å½±å“å¦ä¸€ä¸ªåˆ†æ”¯

### **å½“å‰å®ç°**ï¼š
```python
# æ¸…æ™°çš„åˆ†æ”¯é€‰æ‹©
if cfg.MODEL.TRANSFORMER_TYPE in ['vit_base_patch16_224', 'ViT-B-16']:
    self.clip = 0  # å¤šå°ºåº¦åˆ†æ”¯
    # æ ‡å‡†ViT + å¤šå°ºåº¦æ»‘åŠ¨çª—å£
elif cfg.MODEL.TRANSFORMER_TYPE == 'ViT-B-16-CLIP':
    self.clip = 1  # CLIPåˆ†æ”¯
    # CLIP + å¤šæ¨¡æ€å¤„ç†
```

è¿™æ ·æ—¢ä¿æŒäº†åŠŸèƒ½çš„å®Œæ•´æ€§ï¼Œåˆé¿å…äº†æ¶æ„å†²çªï¼Œæ˜¯æœ€å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚
