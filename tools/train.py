"""
MambaPro è®­ç»ƒå…¥å£è„šæœ¬ï¼ˆä¸­æ–‡è¯´æ˜ï¼‰

åŠŸèƒ½æ¦‚è¿°ï¼š
- è§£æå‘½ä»¤è¡Œå‚æ•°ä¸ YAML é…ç½®ï¼Œåˆå¹¶åˆ°å…¨å±€é…ç½® `cfg`
- è®¾ç½®éšæœºç§å­ã€å¯è§ GPUã€åˆ†å¸ƒå¼ï¼ˆå¯é€‰ï¼‰ä¸æ—¥å¿—
- æ„å»ºæ•°æ®åŠ è½½å™¨ã€æ¨¡å‹ã€æŸå¤±ã€ä¼˜åŒ–å™¨ä¸å­¦ä¹ ç‡è°ƒåº¦å™¨
- è°ƒç”¨è®­ç»ƒå¼•æ“ `engine.processor.do_train` æ‰§è¡Œå®Œæ•´è®­ç»ƒè¿‡ç¨‹

å¸¸ç”¨å¯åŠ¨æ–¹å¼ç¤ºä¾‹ï¼š
    python tools/train.py --config_file configs/RGBNT201/MambaPro.yml

å…³é”®å‚æ•°ï¼š
- --config_file: æŒ‡å®š YAML é…ç½®æ–‡ä»¶è·¯å¾„
- opts: é€šè¿‡å‘½ä»¤è¡ŒåŠ¨æ€è¦†ç›–é…ç½®ï¼Œå¦‚ DATASETS.NAMES RGBNT201 ç­‰

è¾“å‡ºï¼š
- æ—¥å¿—ä¸æƒé‡ä¿å­˜åˆ° `cfg.OUTPUT_DIR`
"""

from utils.logger import setup_logger
from data import make_dataloader
from modeling import make_model
from solver.make_optimizer import make_optimizer
from solver.scheduler_factory import create_scheduler
from layers.make_loss import make_loss
from engine.processor import do_train
import random
import torch
import numpy as np
import os
import argparse
from config import cfg


def set_seed(seed):
    torch.manual_seed(seed)  # è®¾ç½®PyTorch CPUä¸Šçš„éšæœºç§å­
    torch.cuda.manual_seed(seed)  # è®¾ç½®PyTorch GPUä¸Šçš„éšæœºç§å­
    torch.cuda.manual_seed_all(seed)  # è®¾ç½®æ‰€æœ‰GPUä¸Šçš„éšæœºç§å­
    np.random.seed(seed)  # è®¾ç½®NumPyçš„éšæœºç§å­
    random.seed(seed)  # è®¾ç½®PythonåŸç”Ÿéšæœºæ¨¡å—çš„ç§å­
    torch.backends.cudnn.deterministic = True  # å¼ºåˆ¶CuDNNä½¿ç”¨ç¡®å®šæ€§ç®—æ³•ï¼ˆå¯å¤ç°ï¼‰
    torch.backends.cudnn.benchmark = True  # å…è®¸CuDNNåœ¨é™æ€è¾“å…¥å½¢çŠ¶æ—¶åŠ é€Ÿï¼ˆéå®Œå…¨å¯å¤ç°ï¼‰



if __name__ == '__main__':

    parser = argparse.ArgumentParser(description="MambaPro Training")  # æ„å»ºå‘½ä»¤è¡Œè§£æå™¨
    parser.add_argument(
        "--config_file", default="", help="path to config file", type=str  # æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„
    )

    parser.add_argument("opts", help="Modify config options using the command-line", default=None,
                        nargs=argparse.REMAINDER)  # å‘½ä»¤è¡Œè¦†ç›–é…ç½®ï¼ˆé”®å€¼å¯¹åˆ—è¡¨ï¼‰
    parser.add_argument("--local_rank", default=0, type=int)  # åˆ†å¸ƒå¼è®­ç»ƒæ—¶ç”± torchrun ä¼ å…¥
    
    # ğŸ”¥ æ–°å¢ï¼šMoEæ¨¡å—å‘½ä»¤è¡Œå¼€å…³
    parser.add_argument("--use_moe", action="store_true", 
                       help="å¯ç”¨å¤šå°ºåº¦MoEç‰¹å¾èåˆæ¨¡å— (é»˜è®¤: False)")
    parser.add_argument("--disable_moe", action="store_true", 
                       help="å¼ºåˆ¶ç¦ç”¨å¤šå°ºåº¦MoEç‰¹å¾èåˆæ¨¡å— (é»˜è®¤: False)")
    args = parser.parse_args()  # è§£æå‚æ•°

    if args.config_file != "":
        cfg.merge_from_file(args.config_file)  # ä» YAML åˆå¹¶é…ç½®
    cfg.merge_from_list(args.opts)  # ä»å‘½ä»¤è¡Œ opts åˆå¹¶è¦†ç›–
    
    # ğŸ”¥ æ–°å¢ï¼šå¤„ç†MoEå‘½ä»¤è¡Œå¼€å…³
    # ä¼˜å…ˆçº§ï¼š--disable_moe > --use_moe > é…ç½®æ–‡ä»¶è®¾ç½®
    if args.disable_moe:
        # å¼ºåˆ¶ç¦ç”¨MoEæ¨¡å—
        cfg.defrost()  # è§£å†»é…ç½®ä»¥ä¿®æ”¹
        cfg.MODEL.USE_MULTI_SCALE_MOE = False
        cfg.freeze()
        print("ğŸ”¥ å‘½ä»¤è¡Œå‚æ•° --disable_moe: å¼ºåˆ¶ç¦ç”¨MoEæ¨¡å—")
    elif args.use_moe:
        # å¯ç”¨MoEæ¨¡å—
        cfg.defrost()  # è§£å†»é…ç½®ä»¥ä¿®æ”¹
        cfg.MODEL.USE_MULTI_SCALE_MOE = True
        # ç¡®ä¿å¤šå°ºåº¦æ»‘åŠ¨çª—å£ä¹Ÿå¯ç”¨
        cfg.MODEL.USE_CLIP_MULTI_SCALE = True
        cfg.freeze()
        print("ğŸ”¥ å‘½ä»¤è¡Œå‚æ•° --use_moe: å¯ç”¨MoEæ¨¡å—")
    
    cfg.freeze()  # å†»ç»“é…ç½®ï¼Œé¿å…è®­ç»ƒä¸­è¢«è¯¯æ”¹

    set_seed(cfg.SOLVER.SEED)  # è®¾å®šéšæœºç§å­

    if cfg.MODEL.DIST_TRAIN:
        torch.cuda.set_device(args.local_rank)  # å¤šå¡åˆ†å¸ƒå¼æ—¶è®¾ç½®å½“å‰è¿›ç¨‹æ‰€ç”¨ GPU

    output_dir = cfg.OUTPUT_DIR  # è¾“å‡ºç›®å½•ï¼ˆæ—¥å¿—/æƒé‡ï¼‰
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)  # è‹¥ä¸å­˜åœ¨åˆ™åˆ›å»º

    logger = setup_logger("MambaPro", output_dir, if_train=True)  # åˆå§‹åŒ–æ—¥å¿—å™¨
    logger.info("Saving model in the path :{}".format(cfg.OUTPUT_DIR))  # æ‰“å°ä¿å­˜è·¯å¾„
    logger.info(args)  # æ‰“å°å¯åŠ¨å‚æ•°
    
    # ğŸ”¥ æ–°å¢ï¼šæ˜¾ç¤ºMoEæ¨¡å—çŠ¶æ€
    moe_status = "å¯ç”¨" if cfg.MODEL.USE_MULTI_SCALE_MOE else "ç¦ç”¨"
    multi_scale_status = "å¯ç”¨" if cfg.MODEL.USE_CLIP_MULTI_SCALE else "ç¦ç”¨"
    logger.info("ğŸ”¥ MoEæ¨¡å—çŠ¶æ€: {}".format(moe_status))
    logger.info("ğŸ”¥ å¤šå°ºåº¦æ»‘åŠ¨çª—å£çŠ¶æ€: {}".format(multi_scale_status))
    if cfg.MODEL.USE_MULTI_SCALE_MOE:
        logger.info("ğŸ”¥ MoEæ»‘åŠ¨çª—å£å°ºåº¦: {}".format(cfg.MODEL.MOE_SCALES))

    if args.config_file != "":
        logger.info("Loaded configuration file {}".format(args.config_file))  # è®°å½•å·²åŠ è½½çš„é…ç½®æ–‡ä»¶
        with open(args.config_file, 'r') as cf:
            config_str = "\n" + cf.read()  # è¯»å–é…ç½®å†…å®¹
            logger.info(config_str)  # æ‰“å°é…ç½®è¯¦æƒ…
    logger.info("Running with config:\n{}".format(cfg))  # æ‰“å°æœ€ç»ˆ cfg

    if cfg.MODEL.DIST_TRAIN:
        torch.distributed.init_process_group(backend='nccl', init_method='env://')  # åˆå§‹åŒ–åˆ†å¸ƒå¼è¿›ç¨‹ç»„

    # é€‰æ‹©GPU
    os.environ['CUDA_VISIBLE_DEVICES'] = cfg.MODEL.DEVICE_ID  # æŒ‡å®šå¯è§ GPUï¼ˆå¦‚ "0,1"ï¼‰
    train_loader, train_loader_normal, val_loader, num_query, num_classes, camera_num, view_num = make_dataloader(cfg)  # æ„å»ºæ•°æ®åŠ è½½å™¨
    print("data is ready")  # æ•°æ®å°±ç»ªæç¤º

    # æ„å»ºæ¨¡å‹ 
    model = make_model(cfg, num_class=num_classes, camera_num=camera_num, view_num=view_num)  # æ„å»ºæ¨¡å‹

    loss_func, center_criterion = make_loss(cfg, num_classes=num_classes)  # æ„å»ºæŸå¤±å‡½æ•°ï¼ˆå« center loss å¯é€‰ï¼‰

    optimizer, optimizer_center = make_optimizer(cfg, model, center_criterion)  # æ„å»ºä¼˜åŒ–å™¨ï¼ˆå« center å‚æ•°ä¼˜åŒ–å™¨ï¼‰

    scheduler = create_scheduler(cfg, optimizer)  # æ„å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
    do_train(
        cfg,  # å…¨å±€é…ç½®
        model,  # æ¨¡å‹
        center_criterion,  # center loss çš„ä¸­å¿ƒå‚æ•°ï¼ˆè‹¥å¯ç”¨ï¼‰
        train_loader,  # è®­ç»ƒæ•°æ®
        val_loader,  # éªŒè¯æ•°æ®
        optimizer,  # ä¸»ä¼˜åŒ–å™¨
        optimizer_center,  # center ä¼˜åŒ–å™¨
        scheduler,  # å­¦ä¹ ç‡è°ƒåº¦
        loss_func,  # å¤åˆæŸå¤±
        num_query, args.local_rank  # éªŒè¯é›† query æ•°é‡ä¸æœ¬åœ° rank
    )  # å¯åŠ¨è®­ç»ƒä¸»å¾ªç¯
