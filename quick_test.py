#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬
ç”¨äºå¿«é€ŸéªŒè¯å¤šå°ºåº¦MoEæ¨¡å—çš„åŠŸèƒ½

ä½œè€…ä¿®æ”¹ï¼šåˆ›å»ºå¿«é€Ÿæµ‹è¯•è„šæœ¬ï¼ŒéªŒè¯æ¨¡å—åŠŸèƒ½è€Œä¸è¿›è¡Œå®Œæ•´è®­ç»ƒ
åŠŸèƒ½ï¼šå¿«é€Ÿæµ‹è¯•æ¨¡å‹åŠ è½½ã€å‰å‘ä¼ æ’­ç­‰åŠŸèƒ½
æ’¤é”€æ–¹æ³•ï¼šåˆ é™¤æ­¤æ–‡ä»¶
"""

import torch
import sys
import os
import argparse
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/home/zubuntu/workspace/yzy/MambaPro')

def test_model_loading():
    """
    æµ‹è¯•æ¨¡å‹åŠ è½½åŠŸèƒ½
    
    ä½œè€…ä¿®æ”¹ï¼šéªŒè¯å¤šå°ºåº¦MoEæ¨¡å—æ˜¯å¦èƒ½æ­£ç¡®åŠ è½½
    åŠŸèƒ½ï¼šæµ‹è¯•æ¨¡å‹åˆå§‹åŒ–å’Œé…ç½®åŠ è½½
    æ’¤é”€æ–¹æ³•ï¼šåˆ é™¤æ­¤å‡½æ•°
    """
    print("ğŸ”§ æµ‹è¯•æ¨¡å‹åŠ è½½åŠŸèƒ½...")
    
    try:
        from modeling.make_model import make_model
        from config import cfg
        
        # æµ‹è¯•åŸºçº¿é…ç½®
        print("ğŸ“‹ æµ‹è¯•åŸºçº¿é…ç½®...")
        cfg.merge_from_file("configs/RGBNT201/MambaPro_baseline.yml")
        cfg.freeze()
        
        # åˆ›å»ºåŸºçº¿æ¨¡å‹
        baseline_model = make_model(cfg, num_class=201, camera_num=6, view_num=2)
        print("âœ… åŸºçº¿æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•MoEé…ç½®
        print("ğŸ“‹ æµ‹è¯•MoEé…ç½®...")
        cfg.merge_from_file("configs/RGBNT201/MambaPro_moe.yml")
        cfg.freeze()
        
        # åˆ›å»ºMoEæ¨¡å‹
        moe_model = make_model(cfg, num_class=201, camera_num=6, view_num=2)
        print("âœ… MoEæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def test_forward_pass():
    """
    æµ‹è¯•å‰å‘ä¼ æ’­åŠŸèƒ½
    
    ä½œè€…ä¿®æ”¹ï¼šéªŒè¯å¤šå°ºåº¦MoEæ¨¡å—çš„å‰å‘ä¼ æ’­æ˜¯å¦æ­£å¸¸
    åŠŸèƒ½ï¼šæµ‹è¯•æ¨¡å‹æ¨ç†è¿‡ç¨‹
    æ’¤é”€æ–¹æ³•ï¼šåˆ é™¤æ­¤å‡½æ•°
    """
    print("ğŸ”„ æµ‹è¯•å‰å‘ä¼ æ’­åŠŸèƒ½...")
    
    try:
        from modeling.make_model import make_model
        from config import cfg
        
        # æµ‹è¯•åŸºçº¿æ¨¡å‹å‰å‘ä¼ æ’­
        print("ğŸ“‹ æµ‹è¯•åŸºçº¿æ¨¡å‹å‰å‘ä¼ æ’­...")
        cfg.merge_from_file("configs/RGBNT201/MambaPro_baseline.yml")
        cfg.freeze()
        
        baseline_model = make_model(cfg, num_class=201, camera_num=6, view_num=2)
        baseline_model.eval()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ® - ä¿®å¤è¾“å…¥æ ¼å¼
        batch_size = 2
        height, width = 256, 128  # å›¾åƒå°ºå¯¸
        channels = 3              # RGBå›¾åƒé€šé“æ•°
        
        test_data = {
            'RGB': torch.randn(batch_size, channels, height, width),  # [B, 3, H, W]
            'NI': torch.randn(batch_size, channels, height, width),   # [B, 3, H, W]
            'TI': torch.randn(batch_size, channels, height, width)    # [B, 3, H, W]
        }
        
        with torch.no_grad():
            baseline_output = baseline_model(test_data)
            print(f"âœ… åŸºçº¿æ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {baseline_output.shape}")
        
        # æµ‹è¯•MoEæ¨¡å‹å‰å‘ä¼ æ’­
        print("ğŸ“‹ æµ‹è¯•MoEæ¨¡å‹å‰å‘ä¼ æ’­...")
        cfg.merge_from_file("configs/RGBNT201/MambaPro_moe.yml")
        cfg.freeze()
        
        moe_model = make_model(cfg, num_class=201, camera_num=6, view_num=2)
        moe_model.eval()
        
        with torch.no_grad():
            moe_output = moe_model(test_data)
            print(f"âœ… MoEæ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {moe_output.shape}")
        
        # æ¯”è¾ƒè¾“å‡ºå½¢çŠ¶
        if baseline_output.shape == moe_output.shape:
            print("âœ… ä¸¤ä¸ªæ¨¡å‹è¾“å‡ºå½¢çŠ¶ä¸€è‡´")
        else:
            print(f"âš ï¸  è¾“å‡ºå½¢çŠ¶ä¸ä¸€è‡´: åŸºçº¿ {baseline_output.shape} vs MoE {moe_output.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def test_multi_scale_moe_module():
    """
    æµ‹è¯•å¤šå°ºåº¦MoEæ¨¡å—
    
    ä½œè€…ä¿®æ”¹ï¼šå•ç‹¬æµ‹è¯•å¤šå°ºåº¦MoEæ¨¡å—çš„åŠŸèƒ½
    åŠŸèƒ½ï¼šéªŒè¯MoEæ¨¡å—çš„å„ä¸ªç»„ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
    æ’¤é”€æ–¹æ³•ï¼šåˆ é™¤æ­¤å‡½æ•°
    """
    print("ğŸ§ª æµ‹è¯•å¤šå°ºåº¦MoEæ¨¡å—...")
    
    try:
        from modeling.fusion_part.multi_scale_moe import MultiScaleMoE, MultiScaleMoEAAM
        
        # æµ‹è¯•å‚æ•°
        batch_size = 2
        seq_len = 197
        dim = 512
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        x = torch.randn(batch_size, seq_len, dim)
        print(f"ğŸ“Š è¾“å…¥æ•°æ®å½¢çŠ¶: {x.shape}")
        
        # æµ‹è¯•MultiScaleMoEæ¨¡å—
        print("ğŸ”§ æµ‹è¯•MultiScaleMoEæ¨¡å—...")
        moe_module = MultiScaleMoE(dim=dim, scales=[4, 8, 16])
        moe_output = moe_module(x)
        print(f"âœ… MultiScaleMoEè¾“å‡ºå½¢çŠ¶: {moe_output.shape}")
        
        # æµ‹è¯•MultiScaleMoEAAMæ¨¡å—
        print("ğŸ”§ æµ‹è¯•MultiScaleMoEAAMæ¨¡å—...")
        
        # æ¨¡æ‹Ÿé…ç½® - ä¿®å¤é…ç½®å¯¹è±¡
        class MockConfig:
            MODEL = type('obj', (object,), {
                'MAMBA_BI': False,
                'TRANSFORMER_TYPE': 'ViT-B-16'
            })()
            DATASETS = type('obj', (object,), {
                'NAMES': 'RGBNT201'
            })()
        
        cfg = MockConfig()
        aam_module = MultiScaleMoEAAM(dim=dim, n_layers=2, cfg=cfg)
        
        # åˆ›å»ºä¸‰ç§æ¨¡æ€çš„æµ‹è¯•æ•°æ®
        r = torch.randn(batch_size, seq_len, dim)
        n = torch.randn(batch_size, seq_len, dim)
        t = torch.randn(batch_size, seq_len, dim)
        
        aam_output = aam_module(r, n, t)
        print(f"âœ… MultiScaleMoEAAMè¾“å‡ºå½¢çŠ¶: {aam_output.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤šå°ºåº¦MoEæ¨¡å—æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """
    ä¸»å‡½æ•°ï¼šæ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    
    ä½œè€…ä¿®æ”¹ï¼šåˆ›å»ºæµ‹è¯•ä¸»æµç¨‹
    åŠŸèƒ½ï¼šæŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰æµ‹è¯•é¡¹ç›®
    æ’¤é”€æ–¹æ³•ï¼šåˆ é™¤æ­¤å‡½æ•°
    """
    parser = argparse.ArgumentParser(description="å¿«é€Ÿæµ‹è¯•å¤šå°ºåº¦MoEæ¨¡å—")
    parser.add_argument("--test", choices=["all", "loading", "forward", "moe"], 
                       default="all", help="é€‰æ‹©æµ‹è¯•é¡¹ç›®")
    
    args = parser.parse_args()
    
    print("ğŸ§ª å¤šå°ºåº¦MoEæ¨¡å—å¿«é€Ÿæµ‹è¯•")
    print("=" * 50)
    print(f"ğŸ“… æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ¯ æµ‹è¯•é¡¹ç›®: {args.test}")
    
    test_results = {}
    
    if args.test in ["all", "loading"]:
        test_results["model_loading"] = test_model_loading()
    
    if args.test in ["all", "forward"]:
        test_results["forward_pass"] = test_forward_pass()
    
    if args.test in ["all", "moe"]:
        test_results["moe_module"] = test_multi_scale_moe_module()
    
    # æ‰“å°æµ‹è¯•ç»“æœ
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 50)
    
    all_passed = True
    for test_name, result in test_results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if not result:
            all_passed = False
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¤šå°ºåº¦MoEæ¨¡å—åŠŸèƒ½æ­£å¸¸ã€‚")
        print("ğŸ’¡ å»ºè®®ï¼šå¯ä»¥å¼€å§‹è¿›è¡Œå®Œæ•´è®­ç»ƒå®éªŒã€‚")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
        print("ğŸ’¡ å»ºè®®ï¼šä¿®å¤é—®é¢˜åå†è¿›è¡Œè®­ç»ƒå®éªŒã€‚")

if __name__ == "__main__":
    main()
