"""
CLIPå…¼å®¹çš„å¤šå°ºåº¦æ»‘åŠ¨çª—å£æ¨¡å—

åŠŸèƒ½ï¼š
- åœ¨ä¿æŒCLIPåˆ†æ”¯å®Œæ•´æ€§çš„åŸºç¡€ä¸Šï¼Œæ·»åŠ å¤šå°ºåº¦æ»‘åŠ¨çª—å£ç‰¹å¾æå–
- é€‚é…CLIPçš„768ç»´ç‰¹å¾åˆ°å¤šå°ºåº¦å¤„ç†
- å®ç°4x4ã€8x8ã€16x16æ»‘åŠ¨çª—å£çš„å¤šå°ºåº¦ç‰¹å¾èåˆ

ä½œè€…ï¼šç”¨æˆ·ä¿®æ”¹
æ—¥æœŸï¼š2024
"""

import torch
import torch.nn as nn
import torch.nn.functional as F


class CLIPMultiScaleSlidingWindow(nn.Module):
    """
    ğŸ”¥ CLIPå…¼å®¹çš„å¤šå°ºåº¦æ»‘åŠ¨çª—å£æ¨¡å—
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    - å®ç°4x4ã€8x8ã€16x16å¤šå°ºåº¦æ»‘åŠ¨çª—å£ç‰¹å¾æå–
    - é€‚é…CLIPçš„512ç»´æŠ•å½±ç‰¹å¾
    - é€šè¿‡MLPèåˆå¤šå°ºåº¦ç‰¹å¾
    """
    
    def __init__(self, feat_dim=512, scales=[4, 8, 16]):
        """
        ğŸ¯ åˆå§‹åŒ–å¤šå°ºåº¦æ»‘åŠ¨çª—å£æ¨¡å—
        
        Args:
            feat_dim (int): ç‰¹å¾ç»´åº¦ï¼ŒCLIPæŠ•å½±è¾“å‡º512ç»´
            scales (list): æ»‘åŠ¨çª—å£å°ºåº¦åˆ—è¡¨ [4, 8, 16]
        """
        super(CLIPMultiScaleSlidingWindow, self).__init__()
        self.feat_dim = feat_dim  # CLIPæŠ•å½±çš„512ç»´è¾“å‡º
        self.scales = scales      # æ»‘åŠ¨çª—å£å°ºåº¦ [4, 8, 16]
        
        # ğŸ”¥ ä¸ºæ¯ä¸ªå°ºåº¦åˆ›å»ºæ»‘åŠ¨çª—å£å¤„ç†å±‚
        # ä½¿ç”¨1Då·ç§¯å®ç°æ»‘åŠ¨çª—å£æ•ˆæœï¼škernel_size=scale, stride=scale
        self.sliding_windows = nn.ModuleList()
        for scale in scales:
            # æ¯ä¸ªå°ºåº¦ç‹¬ç«‹å¤„ç†ï¼š4x4, 8x8, 16x16
            self.sliding_windows.append(
                nn.Conv1d(feat_dim, feat_dim, kernel_size=scale, stride=scale, padding=0)
            )
        
        # ğŸ”¥ ç‰¹å¾èåˆå±‚ (MLP) - å…³é”®åˆ›æ–°ç‚¹
        # å°†æ‰€æœ‰å°ºåº¦çš„ç‰¹å¾æ‹¼æ¥åï¼Œé€šè¿‡MLPèåˆå›åŸå§‹ç»´åº¦
        self.fusion = nn.Sequential(
            nn.Linear(feat_dim * len(scales), feat_dim), # ç¬¬ä¸€å±‚ï¼š1536 -> 512 (3ä¸ªå°ºåº¦Ã—512ç»´)
            nn.ReLU(),                                   # æ¿€æ´»å‡½æ•°
            nn.Dropout(0.1),                             # Dropoutæ­£åˆ™åŒ–
            nn.Linear(feat_dim, feat_dim)                # ç¬¬äºŒå±‚ï¼š512 -> 512 (ä¿æŒç»´åº¦)
        )
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
        
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Conv1d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
        
    def forward(self, patch_tokens):
        """
        ğŸ¯ å¤šå°ºåº¦æ»‘åŠ¨çª—å£å‰å‘ä¼ æ’­
        
        Args:
            patch_tokens: [B, N, 512] - CLIPæŠ•å½±çš„patch tokens
        Returns:
            multi_scale_feature: [B, 512] - å¤šå°ºåº¦èåˆç‰¹å¾
        """
        B, N, D = patch_tokens.shape
        
        # ğŸ”¥ è½¬æ¢ä¸ºå·ç§¯è¾“å…¥æ ¼å¼ [B, D, N]
        # 1Då·ç§¯éœ€è¦ [B, C, L] æ ¼å¼ï¼Œæ‰€ä»¥éœ€è¦è½¬ç½®
        x = patch_tokens.transpose(1, 2)  # [B, 512, N]
        
        multi_scale_features = []
        for i, scale in enumerate(self.scales):
            # ğŸ”¥ æ»‘åŠ¨çª—å£å¤„ç† - æ ¸å¿ƒç®—æ³•
            if N >= scale:
                # ä½¿ç”¨1Då·ç§¯è¿›è¡Œæ»‘åŠ¨çª—å£å¤„ç†
                # æ¯ä¸ªçª—å£å¤„ç†scaleä¸ªtokensï¼Œè¾“å‡ºN//scaleä¸ªç‰¹å¾
                windowed_feat = self.sliding_windows[i](x)  # [B, 512, N//scale]
                # å…¨å±€å¹³å‡æ± åŒ–ï¼šå°†æ¯ä¸ªå°ºåº¦çš„ç‰¹å¾èšåˆä¸ºå•ä¸ªå‘é‡
                pooled_feat = F.adaptive_avg_pool1d(windowed_feat, 1)  # [B, 512, 1]
                pooled_feat = pooled_feat.squeeze(-1)  # [B, 512]
            else:
                # å¦‚æœåºåˆ—é•¿åº¦å°äºçª—å£å¤§å°ï¼Œç›´æ¥ä½¿ç”¨å…¨å±€å¹³å‡æ± åŒ–
                pooled_feat = F.adaptive_avg_pool1d(x, 1).squeeze(-1)  # [B, 512]
            
            multi_scale_features.append(pooled_feat)
        
        # ğŸ”¥ æ‹¼æ¥å¤šå°ºåº¦ç‰¹å¾
        # å°†3ä¸ªå°ºåº¦çš„ç‰¹å¾æ‹¼æ¥ï¼š4x4 + 8x8 + 16x16 = 1536ç»´
        concat_feat = torch.cat(multi_scale_features, dim=1)  # [B, 512*3] = [B, 1536]
        
        # ğŸ”¥ ç‰¹å¾èåˆ (MLP) - å…³é”®åˆ›æ–°ç‚¹
        # é€šè¿‡ä¸¤å±‚MLPå°†1536ç»´èåˆå›512ç»´
        multi_scale_feature = self.fusion(concat_feat)  # [B, 1536] -> [B, 512]
        
        return multi_scale_feature


class CLIPMultiScaleFeatureExtractor(nn.Module):
    """CLIPå¤šå°ºåº¦ç‰¹å¾æå–å™¨åŒ…è£…ç±»"""
    
    def __init__(self, feat_dim=512, scales=[4, 8, 16]):
        """
        åˆå§‹åŒ–CLIPå¤šå°ºåº¦ç‰¹å¾æå–å™¨
        
        Args:
            feat_dim (int): ç‰¹å¾ç»´åº¦ï¼ŒCLIPæŠ•å½±è¾“å‡º512ç»´
            scales (list): æ»‘åŠ¨çª—å£å°ºåº¦åˆ—è¡¨
        """
        super(CLIPMultiScaleFeatureExtractor, self).__init__()
        self.multi_scale_window = CLIPMultiScaleSlidingWindow(feat_dim, scales)
        
    def forward(self, patch_tokens):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            patch_tokens: [B, N, 512] - CLIPæŠ•å½±çš„patch tokens
        Returns:
            multi_scale_feature: [B, 512] - å¤šå°ºåº¦ç‰¹å¾
        """
        return self.multi_scale_window(patch_tokens)


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 2
    seq_len = 196  # 14x14 patches
    feat_dim = 768  # CLIPå®é™…ç»´åº¦
    
    # åˆ›å»ºæ¨¡å‹
    model = CLIPMultiScaleFeatureExtractor(feat_dim=feat_dim, scales=[4, 8, 16])
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    patch_tokens = torch.randn(batch_size, seq_len, feat_dim)
    
    print("=== CLIPå¤šå°ºåº¦æ»‘åŠ¨çª—å£æ¨¡å—æµ‹è¯• ===")
    print(f"è¾“å…¥å½¢çŠ¶: {patch_tokens.shape}")
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        multi_scale_feature = model(patch_tokens)
    
    print(f"è¾“å‡ºå½¢çŠ¶: {multi_scale_feature.shape}")
    print(f"æœŸæœ›å½¢çŠ¶: [{batch_size}, {feat_dim}]")
    
    # éªŒè¯è¾“å‡ºå½¢çŠ¶
    assert multi_scale_feature.shape == (batch_size, feat_dim), f"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: {multi_scale_feature.shape}"
    
    print("âœ… æµ‹è¯•é€šè¿‡ï¼CLIPå¤šå°ºåº¦æ»‘åŠ¨çª—å£æ¨¡å—å·¥ä½œæ­£å¸¸")
    print(f"   - è¾“å…¥: {patch_tokens.shape}")
    print(f"   - è¾“å‡º: {multi_scale_feature.shape}")
    print(f"   - æ»‘åŠ¨çª—å£å°ºåº¦: [4, 8, 16]")
    print(f"   - ç‰¹å¾ç»´åº¦: {feat_dim}")
