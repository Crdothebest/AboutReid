"""
å¤šå°ºåº¦Mixture-of-Experts (MoE) ç‰¹å¾èåˆæ¨¡å—

åŠŸèƒ½ï¼š
- åœ¨ç°æœ‰å¤šå°ºåº¦æ»‘åŠ¨çª—å£åŸºç¡€ä¸Šï¼Œæ·»åŠ MoEä¸“å®¶ç½‘ç»œæœºåˆ¶
- é€šè¿‡é—¨æ§ç½‘ç»œåŠ¨æ€è®¡ç®—ä¸“å®¶æƒé‡
- å®ç°ä¸“ä¸šåŒ–å¤„ç†ä¸åŒå°ºåº¦ç‰¹å¾

ä½œè€…ï¼šåŸºäºidea-01.pngè®¾è®¡
æ—¥æœŸï¼š2024
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import math


class ExpertNetwork(nn.Module):
    """
    ğŸ”¥ ä¸“å®¶ç½‘ç»œæ¨¡å—
    
    æ¯ä¸ªä¸“å®¶ä¸“é—¨å¤„ç†ç‰¹å®šå°ºåº¦çš„ç‰¹å¾ï¼Œå®ç°ä¸“ä¸šåŒ–åˆ†å·¥
    """
    
    def __init__(self, input_dim=512, hidden_dim=1024, output_dim=512, dropout=0.1):
        """
        åˆå§‹åŒ–ä¸“å®¶ç½‘ç»œ
        
        Args:
            input_dim (int): è¾“å…¥ç‰¹å¾ç»´åº¦
            hidden_dim (int): éšè—å±‚ç»´åº¦
            output_dim (int): è¾“å‡ºç‰¹å¾ç»´åº¦
            dropout (float): Dropoutæ¯”ä¾‹
        """
        super(ExpertNetwork, self).__init__()
        
        # ğŸ”¥ ä¸“å®¶ç½‘ç»œç»“æ„ï¼šä¸¤å±‚MLP + æ®‹å·®è¿æ¥
        self.expert = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, output_dim),
            nn.LayerNorm(output_dim),
            nn.GELU(),
            nn.Dropout(dropout)
        )
        
        # æ®‹å·®è¿æ¥çš„æŠ•å½±å±‚ï¼ˆå¦‚æœè¾“å…¥è¾“å‡ºç»´åº¦ä¸åŒï¼‰
        self.residual_proj = nn.Linear(input_dim, output_dim) if input_dim != output_dim else nn.Identity()
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        """
        ä¸“å®¶ç½‘ç»œå‰å‘ä¼ æ’­
        
        Args:
            x: [B, D] - è¾“å…¥ç‰¹å¾
        Returns:
            output: [B, D] - ä¸“å®¶å¤„ç†åçš„ç‰¹å¾
        """
        # ä¸“å®¶å¤„ç†
        expert_output = self.expert(x)
        
        # æ®‹å·®è¿æ¥
        residual = self.residual_proj(x)
        output = expert_output + residual
        
        return output


class GatingNetwork(nn.Module):
    """
    ğŸ”¥ é—¨æ§ç½‘ç»œæ¨¡å—
    
    æ ¹æ®è¾“å…¥ç‰¹å¾åŠ¨æ€è®¡ç®—å„ä¸“å®¶çš„æƒé‡åˆ†å¸ƒ
    """
    
    def __init__(self, input_dim=1536, num_experts=3, temperature=1.0):
        """
        åˆå§‹åŒ–é—¨æ§ç½‘ç»œ
        
        Args:
            input_dim (int): è¾“å…¥ç‰¹å¾ç»´åº¦ï¼ˆå¤šå°ºåº¦ç‰¹å¾æ‹¼æ¥åçš„ç»´åº¦ï¼‰
            num_experts (int): ä¸“å®¶æ•°é‡
            temperature (float): æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶æƒé‡åˆ†å¸ƒçš„å°–é”ç¨‹åº¦
        """
        super(GatingNetwork, self).__init__()
        self.num_experts = num_experts
        self.temperature = temperature
        
        # ğŸ”¥ é—¨æ§ç½‘ç»œï¼šä¸¤å±‚MLP
        self.gate = nn.Sequential(
            nn.Linear(input_dim, input_dim // 2),
            nn.LayerNorm(input_dim // 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(input_dim // 2, num_experts)
        )
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        """
        é—¨æ§ç½‘ç»œå‰å‘ä¼ æ’­
        
        Args:
            x: [B, input_dim] - å¤šå°ºåº¦ç‰¹å¾æ‹¼æ¥
        Returns:
            weights: [B, num_experts] - ä¸“å®¶æƒé‡åˆ†å¸ƒ
        """
        # è®¡ç®—é—¨æ§åˆ†æ•°
        gate_scores = self.gate(x)  # [B, num_experts]
        
        # åº”ç”¨æ¸©åº¦å‚æ•°
        gate_scores = gate_scores / self.temperature
        
        # Softmaxå½’ä¸€åŒ–å¾—åˆ°æƒé‡åˆ†å¸ƒ
        weights = F.softmax(gate_scores, dim=-1)  # [B, num_experts]
        
        return weights


class MultiScaleMoE(nn.Module):
    """
    ğŸ”¥ å¤šå°ºåº¦Mixture-of-Expertsæ¨¡å—
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    - æ¥æ”¶å¤šå°ºåº¦ç‰¹å¾ï¼ˆ4x4, 8x8, 16x16ï¼‰
    - é€šè¿‡é—¨æ§ç½‘ç»œè®¡ç®—ä¸“å®¶æƒé‡
    - ä½¿ç”¨ä¸“å®¶ç½‘ç»œå¤„ç†å¯¹åº”å°ºåº¦ç‰¹å¾
    - åŠ æƒèåˆå¾—åˆ°æœ€ç»ˆç‰¹å¾
    """
    
    def __init__(self, feat_dim=512, scales=[4, 8, 16], expert_hidden_dim=1024, temperature=1.0):
        """
        åˆå§‹åŒ–å¤šå°ºåº¦MoEæ¨¡å—
        
        Args:
            feat_dim (int): ç‰¹å¾ç»´åº¦
            scales (list): æ»‘åŠ¨çª—å£å°ºåº¦åˆ—è¡¨
            expert_hidden_dim (int): ä¸“å®¶ç½‘ç»œéšè—å±‚ç»´åº¦
            temperature (float): é—¨æ§ç½‘ç»œæ¸©åº¦å‚æ•°
        """
        super(MultiScaleMoE, self).__init__()
        self.feat_dim = feat_dim
        self.scales = scales
        self.num_experts = len(scales)
        
        # ğŸ”¥ ä¸ºæ¯ä¸ªå°ºåº¦åˆ›å»ºä¸“é—¨çš„ä¸“å®¶ç½‘ç»œ
        self.experts = nn.ModuleList()
        for i, scale in enumerate(scales):
            expert = ExpertNetwork(
                input_dim=feat_dim,
                hidden_dim=expert_hidden_dim,
                output_dim=feat_dim,
                dropout=0.1
            )
            self.experts.append(expert)
        
        # ğŸ”¥ é—¨æ§ç½‘ç»œï¼šæ ¹æ®å¤šå°ºåº¦ç‰¹å¾è®¡ç®—ä¸“å®¶æƒé‡
        gate_input_dim = feat_dim * len(scales)  # 1536ç»´ï¼ˆ3ä¸ªå°ºåº¦Ã—512ç»´ï¼‰
        self.gating_network = GatingNetwork(
            input_dim=gate_input_dim,
            num_experts=self.num_experts,
            temperature=temperature
        )
        
        # ğŸ”¥ æœ€ç»ˆèåˆå±‚ï¼šå°†ä¸“å®¶è¾“å‡ºèåˆä¸ºå•ä¸€ç‰¹å¾
        self.final_fusion = nn.Sequential(
            nn.Linear(feat_dim, feat_dim),
            nn.LayerNorm(feat_dim),
            nn.GELU(),
            nn.Dropout(0.1)
        )
        
        print(f"ğŸ”¥ å¤šå°ºåº¦MoEæ¨¡å—åˆå§‹åŒ–å®Œæˆ:")
        print(f"   - ç‰¹å¾ç»´åº¦: {feat_dim}")
        print(f"   - æ»‘åŠ¨çª—å£å°ºåº¦: {scales}")
        print(f"   - ä¸“å®¶æ•°é‡: {self.num_experts}")
        print(f"   - é—¨æ§è¾“å…¥ç»´åº¦: {gate_input_dim}")
        print(f"   - ä¸“å®¶éšè—å±‚ç»´åº¦: {expert_hidden_dim}")
    
    def forward(self, multi_scale_features):
        """
        å¤šå°ºåº¦MoEå‰å‘ä¼ æ’­
        
        Args:
            multi_scale_features: List[Tensor] - å¤šå°ºåº¦ç‰¹å¾åˆ—è¡¨
                               æ¯ä¸ªå…ƒç´ å½¢çŠ¶ä¸º [B, feat_dim]
        Returns:
            final_feature: [B, feat_dim] - MoEèåˆåçš„æœ€ç»ˆç‰¹å¾
            expert_weights: [B, num_experts] - ä¸“å®¶æƒé‡åˆ†å¸ƒï¼ˆç”¨äºåˆ†æï¼‰
        """
        B = multi_scale_features[0].shape[0]
        
        # ğŸ”¥ æ­¥éª¤1ï¼šæ‹¼æ¥å¤šå°ºåº¦ç‰¹å¾ä½œä¸ºé—¨æ§ç½‘ç»œè¾“å…¥
        concat_features = torch.cat(multi_scale_features, dim=1)  # [B, feat_dim * num_scales]
        
        # ğŸ”¥ æ­¥éª¤2ï¼šé—¨æ§ç½‘ç»œè®¡ç®—ä¸“å®¶æƒé‡
        expert_weights = self.gating_network(concat_features)  # [B, num_experts]
        
        # ğŸ”¥ æ­¥éª¤3ï¼šä¸“å®¶ç½‘ç»œå¤„ç†å¯¹åº”å°ºåº¦ç‰¹å¾
        expert_outputs = []
        for i, (expert, feature) in enumerate(zip(self.experts, multi_scale_features)):
            expert_output = expert(feature)  # [B, feat_dim]
            expert_outputs.append(expert_output)
        
        # ğŸ”¥ æ­¥éª¤4ï¼šåŠ æƒèåˆä¸“å®¶è¾“å‡º
        # å°†ä¸“å®¶æƒé‡å¹¿æ’­åˆ°ç‰¹å¾ç»´åº¦
        weighted_outputs = []
        for i, expert_output in enumerate(expert_outputs):
            # expert_weights[:, i] å½¢çŠ¶ä¸º [B]ï¼Œéœ€è¦æ‰©å±•ä¸º [B, feat_dim]
            weight = expert_weights[:, i:i+1].expand_as(expert_output)  # [B, feat_dim]
            weighted_output = weight * expert_output  # [B, feat_dim]
            weighted_outputs.append(weighted_output)
        
        # æ±‚å’Œå¾—åˆ°èåˆç‰¹å¾
        fused_feature = torch.sum(torch.stack(weighted_outputs, dim=0), dim=0)  # [B, feat_dim]
        
        # ğŸ”¥ æ­¥éª¤5ï¼šæœ€ç»ˆèåˆå±‚å¤„ç†
        final_feature = self.final_fusion(fused_feature)  # [B, feat_dim]
        
        return final_feature, expert_weights
    
    def get_expert_usage_stats(self, expert_weights):
        """
        è·å–ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            expert_weights: [B, num_experts] - ä¸“å®¶æƒé‡åˆ†å¸ƒ
        Returns:
            stats: dict - ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡
        """
        with torch.no_grad():
            # è®¡ç®—æ¯ä¸ªä¸“å®¶çš„å¹³å‡æƒé‡
            avg_weights = torch.mean(expert_weights, dim=0)  # [num_experts]
            
            # è®¡ç®—æ¯ä¸ªä¸“å®¶çš„æ¿€æ´»ç‡ï¼ˆæƒé‡>é˜ˆå€¼çš„æ¯”ä¾‹ï¼‰
            threshold = 0.1
            activation_rates = torch.mean((expert_weights > threshold).float(), dim=0)  # [num_experts]
            
            stats = {
                'avg_weights': avg_weights.cpu().numpy(),
                'activation_rates': activation_rates.cpu().numpy(),
                'scale_names': [f'{scale}x{scale}' for scale in self.scales]
            }
            
            return stats


class CLIPMultiScaleMoE(nn.Module):
    """
    ğŸ”¥ CLIPå…¼å®¹çš„å¤šå°ºåº¦MoEç‰¹å¾æå–å™¨
    
    é›†æˆå¤šå°ºåº¦æ»‘åŠ¨çª—å£å’ŒMoEæœºåˆ¶
    """
    
    def __init__(self, feat_dim=512, scales=[4, 8, 16], expert_hidden_dim=1024, temperature=1.0):
        """
        åˆå§‹åŒ–CLIPå¤šå°ºåº¦MoEæ¨¡å—
        
        Args:
            feat_dim (int): ç‰¹å¾ç»´åº¦
            scales (list): æ»‘åŠ¨çª—å£å°ºåº¦åˆ—è¡¨
            expert_hidden_dim (int): ä¸“å®¶ç½‘ç»œéšè—å±‚ç»´åº¦
            temperature (float): é—¨æ§ç½‘ç»œæ¸©åº¦å‚æ•°
        """
        super(CLIPMultiScaleMoE, self).__init__()
        self.feat_dim = feat_dim
        self.scales = scales
        
        # ğŸ”¥ å¤šå°ºåº¦æ»‘åŠ¨çª—å£å¤„ç†ï¼ˆå¤ç”¨ç°æœ‰å®ç°ï¼‰
        from .clip_multi_scale_sliding_window import CLIPMultiScaleSlidingWindow
        self.multi_scale_extractor = CLIPMultiScaleSlidingWindow(feat_dim, scales)
        
        # ğŸ”¥ MoEèåˆæ¨¡å—
        self.moe_fusion = MultiScaleMoE(
            feat_dim=feat_dim,
            scales=scales,
            expert_hidden_dim=expert_hidden_dim,
            temperature=temperature
        )
        
        print(f"ğŸ”¥ CLIPå¤šå°ºåº¦MoEæ¨¡å—åˆå§‹åŒ–å®Œæˆ:")
        print(f"   - ç‰¹å¾ç»´åº¦: {feat_dim}")
        print(f"   - æ»‘åŠ¨çª—å£å°ºåº¦: {scales}")
        print(f"   - ä¸“å®¶éšè—å±‚ç»´åº¦: {expert_hidden_dim}")
    
    def forward(self, patch_tokens):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            patch_tokens: [B, N, feat_dim] - CLIP patch tokens
        Returns:
            final_feature: [B, feat_dim] - MoEèåˆåçš„ç‰¹å¾
            expert_weights: [B, num_experts] - ä¸“å®¶æƒé‡åˆ†å¸ƒ
        """
        # ğŸ”¥ æ­¥éª¤1ï¼šå¤šå°ºåº¦æ»‘åŠ¨çª—å£ç‰¹å¾æå–
        # è¿™é‡Œéœ€è¦ä¿®æ”¹ç°æœ‰çš„å¤šå°ºåº¦æå–å™¨ï¼Œè¿”å›å„ä¸ªå°ºåº¦çš„ç‰¹å¾è€Œä¸æ˜¯èåˆåçš„ç‰¹å¾
        multi_scale_features = self._extract_multi_scale_features(patch_tokens)
        
        # ğŸ”¥ æ­¥éª¤2ï¼šMoEèåˆ
        final_feature, expert_weights = self.moe_fusion(multi_scale_features)
        
        return final_feature, expert_weights
    
    def _extract_multi_scale_features(self, patch_tokens):
        """
        æå–å¤šå°ºåº¦ç‰¹å¾ï¼ˆä¿®æ”¹ç°æœ‰å®ç°ä»¥è¿”å›å„å°ºåº¦ç‰¹å¾ï¼‰
        
        Args:
            patch_tokens: [B, N, feat_dim] - CLIP patch tokens
        Returns:
            multi_scale_features: List[Tensor] - å„å°ºåº¦ç‰¹å¾åˆ—è¡¨
        """
        B, N, D = patch_tokens.shape
        
        # è½¬æ¢ä¸ºå·ç§¯è¾“å…¥æ ¼å¼
        x = patch_tokens.transpose(1, 2)  # [B, feat_dim, N]
        
        multi_scale_features = []
        for i, scale in enumerate(self.scales):
            if N >= scale:
                # ä½¿ç”¨1Då·ç§¯è¿›è¡Œæ»‘åŠ¨çª—å£å¤„ç†
                windowed_feat = self.multi_scale_extractor.sliding_windows[i](x)  # [B, feat_dim, N//scale]
                # å…¨å±€å¹³å‡æ± åŒ–
                pooled_feat = F.adaptive_avg_pool1d(windowed_feat, 1).squeeze(-1)  # [B, feat_dim]
            else:
                # å¦‚æœåºåˆ—é•¿åº¦å°äºçª—å£å¤§å°ï¼Œç›´æ¥ä½¿ç”¨å…¨å±€å¹³å‡æ± åŒ–
                pooled_feat = F.adaptive_avg_pool1d(x, 1).squeeze(-1)  # [B, feat_dim]
            
            multi_scale_features.append(pooled_feat)
        
        return multi_scale_features


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("=== å¤šå°ºåº¦MoEæ¨¡å—æµ‹è¯• ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 2
    seq_len = 196  # 14x14 patches
    feat_dim = 512
    
    # åˆ›å»ºæ¨¡å‹
    model = CLIPMultiScaleMoE(feat_dim=feat_dim, scales=[4, 8, 16])
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    patch_tokens = torch.randn(batch_size, seq_len, feat_dim)
    
    print(f"è¾“å…¥å½¢çŠ¶: {patch_tokens.shape}")
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        final_feature, expert_weights = model(patch_tokens)
    
    print(f"è¾“å‡ºç‰¹å¾å½¢çŠ¶: {final_feature.shape}")
    print(f"ä¸“å®¶æƒé‡å½¢çŠ¶: {expert_weights.shape}")
    print(f"ä¸“å®¶æƒé‡åˆ†å¸ƒ:")
    for i, scale in enumerate([4, 8, 16]):
        avg_weight = torch.mean(expert_weights[:, i]).item()
        print(f"  {scale}x{scale}çª—å£ä¸“å®¶: {avg_weight:.4f}")
    
    # è·å–ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡
    stats = model.moe_fusion.get_expert_usage_stats(expert_weights)
    print(f"ä¸“å®¶æ¿€æ´»ç‡: {stats['activation_rates']}")
    
    print("âœ… å¤šå°ºåº¦MoEæ¨¡å—æµ‹è¯•é€šè¿‡ï¼")
