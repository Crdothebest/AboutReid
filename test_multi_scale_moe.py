#!/usr/bin/env python3
"""
å¤šå°ºåº¦MoEæ¨¡å—æµ‹è¯•è„šæœ¬

åŠŸèƒ½ï¼š
- æµ‹è¯•å¤šå°ºåº¦MoEæ¨¡å—çš„åŸºæœ¬åŠŸèƒ½
- éªŒè¯ä¸“å®¶æƒé‡è®¡ç®—å’Œç‰¹å¾èåˆ
- å¯¹æ¯”ä¼ ç»ŸMLPèåˆå’ŒMoEèåˆçš„æ•ˆæœ

ä½œè€…ï¼šåŸºäºidea-01.pngè®¾è®¡
æ—¥æœŸï¼š2024
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from modeling.fusion_part.multi_scale_moe import CLIPMultiScaleMoE, MultiScaleMoE
from modeling.fusion_part.clip_multi_scale_sliding_window import CLIPMultiScaleFeatureExtractor


def test_moe_basic_functionality():
    """æµ‹è¯•MoEæ¨¡å—åŸºæœ¬åŠŸèƒ½"""
    print("=== æµ‹è¯•MoEæ¨¡å—åŸºæœ¬åŠŸèƒ½ ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 4
    seq_len = 196  # 14x14 patches
    feat_dim = 512
    
    # åˆ›å»ºæ¨¡å‹
    model = CLIPMultiScaleMoE(feat_dim=feat_dim, scales=[4, 8, 16])
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    patch_tokens = torch.randn(batch_size, seq_len, feat_dim)
    
    print(f"è¾“å…¥å½¢çŠ¶: {patch_tokens.shape}")
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        final_feature, expert_weights = model(patch_tokens)
    
    print(f"è¾“å‡ºç‰¹å¾å½¢çŠ¶: {final_feature.shape}")
    print(f"ä¸“å®¶æƒé‡å½¢çŠ¶: {expert_weights.shape}")
    
    # éªŒè¯è¾“å‡ºå½¢çŠ¶
    assert final_feature.shape == (batch_size, feat_dim), f"è¾“å‡ºç‰¹å¾å½¢çŠ¶ä¸åŒ¹é…: {final_feature.shape}"
    assert expert_weights.shape == (batch_size, 3), f"ä¸“å®¶æƒé‡å½¢çŠ¶ä¸åŒ¹é…: {expert_weights.shape}"
    
    # éªŒè¯ä¸“å®¶æƒé‡å½’ä¸€åŒ–
    weight_sums = torch.sum(expert_weights, dim=1)
    assert torch.allclose(weight_sums, torch.ones(batch_size), atol=1e-6), "ä¸“å®¶æƒé‡æœªæ­£ç¡®å½’ä¸€åŒ–"
    
    print("âœ… MoEæ¨¡å—åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
    return model, expert_weights


def test_expert_weight_analysis():
    """æµ‹è¯•ä¸“å®¶æƒé‡åˆ†æåŠŸèƒ½"""
    print("\n=== æµ‹è¯•ä¸“å®¶æƒé‡åˆ†æåŠŸèƒ½ ===")
    
    # åˆ›å»ºæ¨¡å‹
    model = CLIPMultiScaleMoE(feat_dim=512, scales=[4, 8, 16])
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 8
    seq_len = 196
    patch_tokens = torch.randn(batch_size, seq_len, 512)
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        final_feature, expert_weights = model(patch_tokens)
    
    # è·å–ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡
    stats = model.moe_fusion.get_expert_usage_stats(expert_weights)
    
    print("ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡:")
    for i, scale_name in enumerate(stats['scale_names']):
        avg_weight = stats['avg_weights'][i]
        activation_rate = stats['activation_rates'][i]
        print(f"  {scale_name}ä¸“å®¶:")
        print(f"    å¹³å‡æƒé‡: {avg_weight:.4f}")
        print(f"    æ¿€æ´»ç‡: {activation_rate:.4f}")
    
    print("âœ… ä¸“å®¶æƒé‡åˆ†æåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
    return stats


def compare_mlp_vs_moe():
    """å¯¹æ¯”MLPèåˆå’ŒMoEèåˆ"""
    print("\n=== å¯¹æ¯”MLPèåˆå’ŒMoEèåˆ ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 4
    seq_len = 196
    feat_dim = 512
    patch_tokens = torch.randn(batch_size, seq_len, feat_dim)
    
    # åˆ›å»ºMLPæ¨¡å‹
    mlp_model = CLIPMultiScaleFeatureExtractor(feat_dim=feat_dim, scales=[4, 8, 16])
    
    # åˆ›å»ºMoEæ¨¡å‹
    moe_model = CLIPMultiScaleMoE(feat_dim=feat_dim, scales=[4, 8, 16])
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        mlp_output = mlp_model(patch_tokens)
        moe_output, expert_weights = moe_model(patch_tokens)
    
    print(f"MLPè¾“å‡ºå½¢çŠ¶: {mlp_output.shape}")
    print(f"MoEè¾“å‡ºå½¢çŠ¶: {moe_output.shape}")
    print(f"ä¸“å®¶æƒé‡å½¢çŠ¶: {expert_weights.shape}")
    
    # è®¡ç®—ç‰¹å¾å·®å¼‚
    feature_diff = torch.norm(mlp_output - moe_output, dim=1)
    print(f"ç‰¹å¾å·®å¼‚ (L2èŒƒæ•°): {feature_diff.mean().item():.6f}")
    
    # åˆ†æä¸“å®¶æƒé‡åˆ†å¸ƒ
    print("\nä¸“å®¶æƒé‡åˆ†å¸ƒ:")
    for i, scale in enumerate([4, 8, 16]):
        avg_weight = torch.mean(expert_weights[:, i]).item()
        std_weight = torch.std(expert_weights[:, i]).item()
        print(f"  {scale}x{scale}çª—å£ä¸“å®¶: {avg_weight:.4f} Â± {std_weight:.4f}")
    
    print("âœ… MLP vs MoEå¯¹æ¯”æµ‹è¯•é€šè¿‡ï¼")
    return mlp_output, moe_output, expert_weights


def visualize_expert_weights(expert_weights, save_path=None):
    """å¯è§†åŒ–ä¸“å®¶æƒé‡åˆ†å¸ƒ"""
    print("\n=== å¯è§†åŒ–ä¸“å®¶æƒé‡åˆ†å¸ƒ ===")
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    weights_np = expert_weights.detach().cpu().numpy()
    
    # åˆ›å»ºå­å›¾
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    scale_names = ['4x4çª—å£', '8x8çª—å£', '16x16çª—å£']
    
    for i, (ax, scale_name) in enumerate(zip(axes, scale_names)):
        # ç»˜åˆ¶æƒé‡åˆ†å¸ƒç›´æ–¹å›¾
        ax.hist(weights_np[:, i], bins=20, alpha=0.7, color=f'C{i}')
        ax.set_title(f'{scale_name}ä¸“å®¶æƒé‡åˆ†å¸ƒ')
        ax.set_xlabel('æƒé‡å€¼')
        ax.set_ylabel('é¢‘æ¬¡')
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        mean_weight = np.mean(weights_np[:, i])
        std_weight = np.std(weights_np[:, i])
        ax.axvline(mean_weight, color='red', linestyle='--', 
                  label=f'å‡å€¼: {mean_weight:.3f}')
        ax.legend()
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ä¸“å®¶æƒé‡åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {save_path}")
    
    plt.show()
    print("âœ… ä¸“å®¶æƒé‡å¯è§†åŒ–å®Œæˆï¼")


def test_different_scales():
    """æµ‹è¯•ä¸åŒå°ºåº¦ç»„åˆçš„æ•ˆæœ"""
    print("\n=== æµ‹è¯•ä¸åŒå°ºåº¦ç»„åˆ ===")
    
    # æµ‹è¯•ä¸åŒçš„å°ºåº¦ç»„åˆ
    scale_combinations = [
        [4, 8],
        [4, 8, 16],
        [4, 8, 16, 32]
    ]
    
    batch_size = 2
    seq_len = 196
    feat_dim = 512
    patch_tokens = torch.randn(batch_size, seq_len, feat_dim)
    
    results = {}
    
    for scales in scale_combinations:
        print(f"\næµ‹è¯•å°ºåº¦ç»„åˆ: {scales}")
        
        # åˆ›å»ºæ¨¡å‹
        model = CLIPMultiScaleMoE(feat_dim=feat_dim, scales=scales)
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            final_feature, expert_weights = model(patch_tokens)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        weight_entropy = -torch.sum(expert_weights * torch.log(expert_weights + 1e-8), dim=1).mean()
        weight_variance = torch.var(expert_weights, dim=1).mean()
        
        results[f'scales_{scales}'] = {
            'weight_entropy': weight_entropy.item(),
            'weight_variance': weight_variance.item(),
            'num_experts': len(scales)
        }
        
        print(f"  ä¸“å®¶æ•°é‡: {len(scales)}")
        print(f"  æƒé‡ç†µ: {weight_entropy.item():.4f}")
        print(f"  æƒé‡æ–¹å·®: {weight_variance.item():.4f}")
    
    print("âœ… ä¸åŒå°ºåº¦ç»„åˆæµ‹è¯•å®Œæˆï¼")
    return results


def test_gradient_flow():
    """æµ‹è¯•æ¢¯åº¦æµ"""
    print("\n=== æµ‹è¯•æ¢¯åº¦æµ ===")
    
    # åˆ›å»ºæ¨¡å‹
    model = CLIPMultiScaleMoE(feat_dim=512, scales=[4, 8, 16])
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 2
    seq_len = 196
    patch_tokens = torch.randn(batch_size, seq_len, 512, requires_grad=True)
    
    # å‰å‘ä¼ æ’­
    final_feature, expert_weights = model(patch_tokens)
    
    # è®¡ç®—æŸå¤±ï¼ˆç®€å•çš„L2æŸå¤±ï¼‰
    target = torch.randn_like(final_feature)
    loss = torch.nn.functional.mse_loss(final_feature, target)
    
    # åå‘ä¼ æ’­
    loss.backward()
    
    # æ£€æŸ¥æ¢¯åº¦
    print(f"è¾“å…¥æ¢¯åº¦èŒƒæ•°: {patch_tokens.grad.norm().item():.6f}")
    
    # æ£€æŸ¥MoEæ¨¡å—çš„æ¢¯åº¦
    for name, param in model.named_parameters():
        if param.grad is not None:
            grad_norm = param.grad.norm().item()
            print(f"{name} æ¢¯åº¦èŒƒæ•°: {grad_norm:.6f}")
    
    print("âœ… æ¢¯åº¦æµæµ‹è¯•é€šè¿‡ï¼")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ”¥ å¤šå°ºåº¦MoEæ¨¡å—å®Œæ•´æµ‹è¯•")
    print("=" * 50)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    try:
        # 1. åŸºæœ¬åŠŸèƒ½æµ‹è¯•
        model, expert_weights = test_moe_basic_functionality()
        
        # 2. ä¸“å®¶æƒé‡åˆ†æ
        stats = test_expert_weight_analysis()
        
        # 3. MLP vs MoEå¯¹æ¯”
        mlp_output, moe_output, expert_weights = compare_mlp_vs_moe()
        
        # 4. å¯è§†åŒ–ä¸“å®¶æƒé‡
        visualize_expert_weights(expert_weights, save_path='expert_weights_distribution.png')
        
        # 5. ä¸åŒå°ºåº¦ç»„åˆæµ‹è¯•
        scale_results = test_different_scales()
        
        # 6. æ¢¯åº¦æµæµ‹è¯•
        test_gradient_flow()
        
        print("\n" + "=" * 50)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¤šå°ºåº¦MoEæ¨¡å—å·¥ä½œæ­£å¸¸")
        print("=" * 50)
        
        # è¾“å‡ºæ€»ç»“
        print("\nğŸ“Š æµ‹è¯•æ€»ç»“:")
        print(f"âœ… åŸºæœ¬åŠŸèƒ½: æ­£å¸¸")
        print(f"âœ… ä¸“å®¶æƒé‡åˆ†æ: æ­£å¸¸")
        print(f"âœ… MLP vs MoEå¯¹æ¯”: æ­£å¸¸")
        print(f"âœ… å¯è§†åŒ–åŠŸèƒ½: æ­£å¸¸")
        print(f"âœ… ä¸åŒå°ºåº¦ç»„åˆ: æ­£å¸¸")
        print(f"âœ… æ¢¯åº¦æµ: æ­£å¸¸")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()


